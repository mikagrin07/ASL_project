{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPTFOvZcFF1oeyiDBJmI0oM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mikagrin07/ASL_project/blob/main/ASL_Classifier/Making_Annotated_Dataset_submission.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upgrades pip and installs a specific version of MediaPipe."
      ],
      "metadata": {
        "id": "uYNtLYtqzXO6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJhkK0c1xHy7"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install mediapipe==0.10.7"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloads the heavy pose landmark model from MediaPipe."
      ],
      "metadata": {
        "id": "wS3LVHT1zdpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O pose_landmarker.task -q https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_heavy/float16/1/pose_landmarker_heavy.task"
      ],
      "metadata": {
        "id": "YpSn1ETKxT47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloads the hand landmark model from MediaPipe."
      ],
      "metadata": {
        "id": "aHPdi6yOzhxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task"
      ],
      "metadata": {
        "id": "olf-7RRZxWx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports MediaPipe, OpenCV, NumPy, and other libraries for processing video and extracting body and hand landmarks."
      ],
      "metadata": {
        "id": "31-v6jRQzoRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mediapipe import solutions\n",
        "from mediapipe.framework.formats import landmark_pb2\n",
        "import cv2\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "from mediapipe.tasks import python\n",
        "from mediapipe.tasks.python import vision\n",
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "KKnCDQVKxdU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mounts Google Drive and sets up tools to display videos in Colab."
      ],
      "metadata": {
        "id": "TD27DVNuvqR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import requests\n",
        "from IPython.display import Video, display\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "iLGjPrgdx3ft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load MediaPipe Hand and Pose Landmarker"
      ],
      "metadata": {
        "id": "OKOTXwoj0DkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_options_hand = python.BaseOptions(model_asset_path='hand_landmarker.task')\n",
        "options_hand = vision.HandLandmarkerOptions(\n",
        "    base_options=base_options_hand,\n",
        "    num_hands=2\n",
        ")\n",
        "hand_landmarker = vision.HandLandmarker.create_from_options(options_hand)\n",
        "\n",
        "base_options_pose = python.BaseOptions(model_asset_path='pose_landmarker.task')\n",
        "options_pose = vision.PoseLandmarkerOptions(\n",
        "    base_options=base_options_pose,\n",
        "    output_segmentation_masks=True\n",
        ")\n",
        "pose_landmarker = vision.PoseLandmarker.create_from_options(options_pose)"
      ],
      "metadata": {
        "id": "1jdn4q2byLpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expected total columns (x, y for each landmark)"
      ],
      "metadata": {
        "id": "wm-sVdwQ0G79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LEFT_HAND_LANDMARKS = 21\n",
        "RIGHT_HAND_LANDMARKS = 21\n",
        "POSE_LANDMARKS = 33\n",
        "TOTAL_COLUMNS = (LEFT_HAND_LANDMARKS + RIGHT_HAND_LANDMARKS + POSE_LANDMARKS) * 2"
      ],
      "metadata": {
        "id": "84ObEtIZyOKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A function that extracts and saves normalized hand and pose landmarks (X, Y only) from a video to a CSV file, frame by frame, using MediaPipe."
      ],
      "metadata": {
        "id": "NaiEAxTM0fLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_and_save_normalized_landmarks(video_path, output_csv_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        print(f\"❌ Error: Could not open video at {video_path}\")\n",
        "        return\n",
        "\n",
        "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Storage for all frames\n",
        "    all_frames_data = []\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Convert to RGB for MediaPipe\n",
        "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        mp_frame = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)\n",
        "\n",
        "        # Detect hand and pose landmarks\n",
        "        hand_result = hand_landmarker.detect(mp_frame)\n",
        "        pose_result = pose_landmarker.detect(mp_frame)\n",
        "\n",
        "        # Initialize a row with zeros (for missing landmarks)\n",
        "        frame_data = [0.0] * TOTAL_COLUMNS\n",
        "\n",
        "        # Store left and right hand landmarks (normalized)\n",
        "        if hand_result.hand_landmarks:\n",
        "            for hand_idx, hand in enumerate(hand_result.hand_landmarks):\n",
        "                # Identify left or right hand\n",
        "                if hand_result.handedness[hand_idx][0].category_name == \"Left\":\n",
        "                    base_idx = 0  # Left hand starts at index 0\n",
        "                else:\n",
        "                    base_idx = LEFT_HAND_LANDMARKS * 2  # Right hand starts after left hand\n",
        "\n",
        "                for landmark_idx, landmark in enumerate(hand):\n",
        "                    x = landmark.x  # Normalized (0 to 1)\n",
        "                    y = landmark.y  # Normalized (0 to 1)\n",
        "                    frame_data[base_idx + landmark_idx * 2] = x\n",
        "                    frame_data[base_idx + landmark_idx * 2 + 1] = y\n",
        "\n",
        "        # Store pose landmarks (normalized)\n",
        "        if pose_result.pose_landmarks:\n",
        "            base_idx = (LEFT_HAND_LANDMARKS + RIGHT_HAND_LANDMARKS) * 2  # Pose starts after both hands\n",
        "            for landmark_idx, landmark in enumerate(pose_result.pose_landmarks[0]):\n",
        "                x = landmark.x  # Normalized (0 to 1)\n",
        "                y = landmark.y  # Normalized (0 to 1)\n",
        "                frame_data[base_idx + landmark_idx * 2] = x\n",
        "                frame_data[base_idx + landmark_idx * 2 + 1] = y\n",
        "\n",
        "        # Append frame data\n",
        "        all_frames_data.append(frame_data)\n",
        "\n",
        "    cap.release()\n",
        "    # Convert to DataFrame and save\n",
        "    df = pd.DataFrame(all_frames_data)\n",
        "    df.to_csv(output_csv_path, index=False, header=False)\n",
        "    print(f\"✅ Saved normalized landmarks (X, Y only) to {output_csv_path}\")"
      ],
      "metadata": {
        "id": "voGAeOuoySH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A function that processes all `.mp4` videos in a folder (and subfolders), extracts landmarks, and saves them as CSVs—skipping files already processed."
      ],
      "metadata": {
        "id": "NwLFui7J0oas"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_all_videos(input_folder, output_folder):\n",
        "    # Walk through all subfolders and videos\n",
        "    for root, dirs, files in os.walk(input_folder):\n",
        "        for file in files:\n",
        "            if file.endswith(\".mp4\"):  # Process only video files\n",
        "                input_video_path = os.path.join(root, file)\n",
        "\n",
        "                # Determine subfolder structure for the output\n",
        "                relative_path = os.path.relpath(root, input_folder)\n",
        "                output_subfolder = os.path.join(output_folder, relative_path)\n",
        "                os.makedirs(output_subfolder, exist_ok=True)  # Ensure subfolder exists\n",
        "\n",
        "                # Output CSV path\n",
        "                output_csv_path = os.path.join(output_subfolder, file.replace('.mp4', '.csv'))\n",
        "\n",
        "                # ✅ Check if the CSV file already exists\n",
        "                if os.path.exists(output_csv_path):\n",
        "                    print(f\"⚠️ Skipping {file}: CSV already exists at {output_csv_path}\")\n",
        "                    continue  # Skip processing\n",
        "\n",
        "                # Process the video\n",
        "                print(f\"📌 Processing: {input_video_path} → {output_csv_path}\")\n",
        "                extract_and_save_normalized_landmarks(input_video_path, output_csv_path)"
      ],
      "metadata": {
        "id": "t__RtApIybSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Processes all training videos by extracting landmarks and saving them as CSVs in the specified output folder."
      ],
      "metadata": {
        "id": "VQD_yZOF0yiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_videos_folder = \"/content/drive/MyDrive/ASL_project/Dataset/train\"\n",
        "output_csv_folder = \"/content/drive/MyDrive/ASL_project/Dataset/landmark_xy\"\n",
        "process_all_videos(input_videos_folder, output_csv_folder)"
      ],
      "metadata": {
        "id": "dZRWtqvKynqX"
      },
      "execution_count": null,
      "outputs": []
    } 
  ]
}