{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Upgrades pip and installs a specific version of MediaPipe."
      ],
      "metadata": {
        "id": "uYNtLYtqzXO6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJhkK0c1xHy7"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install mediapipe==0.10.7"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloads the heavy pose landmark model from MediaPipe."
      ],
      "metadata": {
        "id": "wS3LVHT1zdpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O pose_landmarker.task -q https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_heavy/float16/1/pose_landmarker_heavy.task"
      ],
      "metadata": {
        "id": "YpSn1ETKxT47"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Downloads the hand landmark model from MediaPipe."
      ],
      "metadata": {
        "id": "aHPdi6yOzhxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task"
      ],
      "metadata": {
        "id": "olf-7RRZxWx7"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports MediaPipe, OpenCV, NumPy, and other libraries for processing video and extracting body and hand landmarks."
      ],
      "metadata": {
        "id": "31-v6jRQzoRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "from mediapipe.tasks import python\n",
        "from mediapipe.tasks.python import vision\n",
        "import pandas as pd\n",
        "import os\n",
        "import random"
      ],
      "metadata": {
        "id": "KKnCDQVKxdU8"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mounts Google Drive and sets up tools to display videos in Colab."
      ],
      "metadata": {
        "id": "TD27DVNuvqR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "iLGjPrgdx3ft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e61a38c4-281c-4883-8dd5-6a2c9347bf23"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Landmarks application"
      ],
      "metadata": {
        "id": "tpfsasaZC2c8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load MediaPipe Hand and Pose Landmarker"
      ],
      "metadata": {
        "id": "OKOTXwoj0DkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load base options for the hand landmark model from the .task file\n",
        "base_options_hand = python.BaseOptions(model_asset_path='hand_landmarker.task')\n",
        "\n",
        "# Configure the hand landmark detector to detect up to 2 hands\n",
        "options_hand = vision.HandLandmarkerOptions(\n",
        "    base_options=base_options_hand,\n",
        "    num_hands=2\n",
        ")\n",
        "\n",
        "# Create the hand landmark detector instance\n",
        "hand_landmarker = vision.HandLandmarker.create_from_options(options_hand)\n",
        "\n",
        "# Load base options for the pose landmark model from the .task file\n",
        "base_options_pose = python.BaseOptions(model_asset_path='pose_landmarker.task')\n",
        "\n",
        "# Configure the pose landmark detector, enabling segmentation masks as well\n",
        "options_pose = vision.PoseLandmarkerOptions(\n",
        "    base_options=base_options_pose,\n",
        "    output_segmentation_masks=True\n",
        ")\n",
        "\n",
        "# Create the pose landmark detector instance\n",
        "pose_landmarker = vision.PoseLandmarker.create_from_options(options_pose)"
      ],
      "metadata": {
        "id": "1jdn4q2byLpD"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expected total columns (x, y for each landmark)"
      ],
      "metadata": {
        "id": "wm-sVdwQ0G79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LEFT_HAND_LANDMARKS = 21\n",
        "RIGHT_HAND_LANDMARKS = 21\n",
        "POSE_LANDMARKS = 33\n",
        "TOTAL_COLUMNS = (LEFT_HAND_LANDMARKS + RIGHT_HAND_LANDMARKS + POSE_LANDMARKS) * 2"
      ],
      "metadata": {
        "id": "84ObEtIZyOKY"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A function that extracts and saves normalized hand and pose landmarks (X, Y only) from a video to a CSV file, frame by frame, using MediaPipe."
      ],
      "metadata": {
        "id": "NaiEAxTM0fLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_and_save_normalized_landmarks(video_path, output_csv_path):\n",
        "    # Open the video file\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        print(f\" Error: Could not open video at {video_path}\")\n",
        "        return\n",
        "\n",
        "    # Get video frame dimensions\n",
        "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Storage for all frames\n",
        "    all_frames_data = []\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Convert to RGB for MediaPipe\n",
        "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        mp_frame = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)\n",
        "\n",
        "        # Detect hand and pose landmarks\n",
        "        hand_result = hand_landmarker.detect(mp_frame)\n",
        "        pose_result = pose_landmarker.detect(mp_frame)\n",
        "\n",
        "        # Initialize a row with zeros (for missing landmarks)\n",
        "        frame_data = [0.0] * TOTAL_COLUMNS\n",
        "\n",
        "        # Store left and right hand landmarks (normalized)\n",
        "        if hand_result.hand_landmarks:\n",
        "            for hand_idx, hand in enumerate(hand_result.hand_landmarks):\n",
        "                # Identify left or right hand\n",
        "                if hand_result.handedness[hand_idx][0].category_name == \"Left\":\n",
        "                    base_idx = 0  # Left hand starts at index 0\n",
        "                else:\n",
        "                    base_idx = LEFT_HAND_LANDMARKS * 2  # Right hand starts after left hand\n",
        "\n",
        "                for landmark_idx, landmark in enumerate(hand):\n",
        "                    x = landmark.x  # Normalized (0 to 1)\n",
        "                    y = landmark.y  # Normalized (0 to 1)\n",
        "                    frame_data[base_idx + landmark_idx * 2] = x\n",
        "                    frame_data[base_idx + landmark_idx * 2 + 1] = y\n",
        "\n",
        "        # Store pose landmarks (normalized)\n",
        "        if pose_result.pose_landmarks:\n",
        "            base_idx = (LEFT_HAND_LANDMARKS + RIGHT_HAND_LANDMARKS) * 2  # Pose starts after both hands\n",
        "            for landmark_idx, landmark in enumerate(pose_result.pose_landmarks[0]):\n",
        "                x = landmark.x  # Normalized (0 to 1)\n",
        "                y = landmark.y  # Normalized (0 to 1)\n",
        "                frame_data[base_idx + landmark_idx * 2] = x\n",
        "                frame_data[base_idx + landmark_idx * 2 + 1] = y\n",
        "\n",
        "        # Append frame data\n",
        "        all_frames_data.append(frame_data)\n",
        "\n",
        "    cap.release()\n",
        "    # Convert to DataFrame and save\n",
        "    df = pd.DataFrame(all_frames_data)\n",
        "    df.to_csv(output_csv_path, index=False, header=False)\n",
        "    print(f\"Saved normalized landmarks (X, Y only) to {output_csv_path}\")"
      ],
      "metadata": {
        "id": "voGAeOuoySH2"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A function that processes all `.mp4` videos in a folder (and subfolders), extracts landmarks, and saves them as CSVsâ€”skipping files already processed."
      ],
      "metadata": {
        "id": "NwLFui7J0oas"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_all_videos(input_folder, output_folder):\n",
        "    # Walk through all subfolders and videos\n",
        "    for root, dirs, files in os.walk(input_folder):\n",
        "        # 'root' is the current directory path\n",
        "        # 'dirs' is a list of subdirectories in 'root' (not used here)\n",
        "        # 'files' is a list of file names in 'root'\n",
        "        for file in files:\n",
        "            # Process only .mp4 video files\n",
        "            if file.endswith(\".mp4\"):\n",
        "                # Full path to the input video file\n",
        "                input_video_path = os.path.join(root, file)\n",
        "\n",
        "                # Relative path of the current directory with respect to the input folder\n",
        "                # This keeps the folder structure consistent in the output\n",
        "                relative_path = os.path.relpath(root, input_folder)\n",
        "\n",
        "                # Full path to the output subfolder where the CSV will be saved\n",
        "                output_subfolder = os.path.join(output_folder, relative_path)\n",
        "\n",
        "                # Create the output subfolder if it doesn't already exist\n",
        "                os.makedirs(output_subfolder, exist_ok=True)\n",
        "                # Output CSV path\n",
        "                output_csv_path = os.path.join(output_subfolder, file.replace('.mp4', '.csv'))\n",
        "\n",
        "                # Check if the CSV file already exists\n",
        "                if os.path.exists(output_csv_path):\n",
        "                    print(f\"Skipping {file}: CSV already exists at {output_csv_path}\")\n",
        "                    continue  # Skip processing\n",
        "\n",
        "                # Process the video\n",
        "                print(f\"Processing: {input_video_path} â†’ {output_csv_path}\")\n",
        "                extract_and_save_normalized_landmarks(input_video_path, output_csv_path)"
      ],
      "metadata": {
        "id": "t__RtApIybSm"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Processes all training videos by extracting landmarks and saving them as CSVs in the specified output folder."
      ],
      "metadata": {
        "id": "VQD_yZOF0yiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_videos_folder = \"/content/drive/MyDrive/ASL_Project_Mika/Dataset_submission/test\"\n",
        "output_csv_folder = \"/content/drive/MyDrive/ASL_Project_Mika/Dataset_submission/annotated_test_data\"\n",
        "process_all_videos(input_videos_folder, output_csv_folder)"
      ],
      "metadata": {
        "id": "dZRWtqvKynqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# augmentaion"
      ],
      "metadata": {
        "id": "FJn8nkMmCxfI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function applies a series of random augmentationsâ€”including noise, scaling, translation, rotation, and optional horizontal flippingâ€”to a given sequence of 2D hand and pose landmarks with shape `(frames, 150)` to increase variability and robustness during training."
      ],
      "metadata": {
        "id": "L9oSDvWWCtoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_sequence(sequence, flip_prob=0.5, noise_level=0.01):\n",
        "    \"\"\"Apply augmentations to a single (30, 150) sequence\"\"\"\n",
        "    # Make a copy of the input so the original isn't modified\n",
        "    seq = np.copy(sequence)\n",
        "\n",
        "    # 1. Add small Gaussian noise\n",
        "    # Adds random variation to simulate sensor noise\n",
        "    seq += np.random.normal(0, noise_level, seq.shape)\n",
        "\n",
        "    # 2. Random scaling\n",
        "    # Multiplies all coordinates by a small random factor (around 1.0)\n",
        "    scale = np.random.uniform(0.95, 1.05)\n",
        "    seq *= scale\n",
        "\n",
        "    # 3. Random translation\n",
        "    # Adds a small constant offset to all coordinates\n",
        "    shift = np.random.uniform(-0.05, 0.05)\n",
        "    seq += shift\n",
        "\n",
        "    # 4. Random rotation (2D)\n",
        "    # Define a helper function to apply 2D rotation\n",
        "    def rotate_coords(xy_array, angle_rad):\n",
        "        # 2x2 rotation matrix\n",
        "        rot_matrix = np.array([\n",
        "            [np.cos(angle_rad), -np.sin(angle_rad)],\n",
        "            [np.sin(angle_rad),  np.cos(angle_rad)]\n",
        "        ])\n",
        "        # Apply rotation matrix to the (N, 2) array\n",
        "        return xy_array @ rot_matrix.T\n",
        "\n",
        "    for t in range(seq.shape[0]): # Loop over each frame\n",
        "        frame = seq[t].reshape(-1, 2) # Reshape (150,) â†’ (75, 2) â†’ (x, y) pairs\n",
        "        angle = np.radians(np.random.uniform(-5, 5)) # Small random angle in radians\n",
        "        rotated = rotate_coords(frame, angle) # Rotate coordinates\n",
        "        seq[t] = rotated.flatten() # Flatten back to 1D (150,)\n",
        "\n",
        "    # 5. Optional horizontal flip\n",
        "    if random.random() < flip_prob:\n",
        "        for t in range(seq.shape[0]):\n",
        "            frame = seq[t].reshape(-1, 2)\n",
        "            frame[:, 0] = 1.0 - frame[:, 0] # Flip X coordinates horizontally\n",
        "            seq[t] = frame.flatten()\n",
        "\n",
        "    return seq"
      ],
      "metadata": {
        "id": "lKNtZOTH-PXz"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function augments landmark CSV files with random transformations and saves them to an output folder, skipping files that already exist."
      ],
      "metadata": {
        "id": "lfFm1SQcDOZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_all_csvs(input_folder, output_folder, num_augmentations=1):\n",
        "    # Walk through all directories and files in the input folder\n",
        "    for root, dirs, files in os.walk(input_folder):\n",
        "        for file in files:\n",
        "            if not file.endswith('.csv'): # Skip non-CSV files\n",
        "                continue\n",
        "\n",
        "            # Get relative path to preserve folder structure\n",
        "            relative_class_path = os.path.relpath(root, input_folder)\n",
        "\n",
        "            # Full path to the input CSV file\n",
        "            input_csv_path = os.path.join(root, file)\n",
        "\n",
        "            # Load the CSV into a NumPy array (each row = frame, shape should be (30, 150))\n",
        "            sequence = pd.read_csv(input_csv_path, header=None).values\n",
        "\n",
        "            # Check for correct shape (150 features per frame)\n",
        "            if sequence.shape[1] != 150:\n",
        "                print(f\"Skipping {file}: incorrect shape {sequence.shape}\")\n",
        "                continue\n",
        "\n",
        "            # Set up output path\n",
        "            output_subfolder = os.path.join(output_folder, relative_class_path)\n",
        "            os.makedirs(output_subfolder, exist_ok=True)\n",
        "\n",
        "            # Save augmentations (only if not already saved)\n",
        "            for i in range(num_augmentations):\n",
        "                # Generate output filename (e.g., sample_aug1.csv)\n",
        "                output_file_name = file.replace('.csv', f'_aug{i+1}.csv')\n",
        "                output_csv_path = os.path.join(output_subfolder, output_file_name)\n",
        "\n",
        "                # Skip if the augmented version already exists\n",
        "                if os.path.exists(output_csv_path):\n",
        "                    print(f\"Skipping {output_file_name}: already exists at {output_csv_path}\")\n",
        "                    continue\n",
        "\n",
        "                # Apply augmentation and save to CSV (no header or index)\n",
        "                aug_sequence = augment_sequence(sequence)\n",
        "                pd.DataFrame(aug_sequence).to_csv(output_csv_path, index=False, header=False)\n",
        "                print(f\"Saved: {output_csv_path}\")"
      ],
      "metadata": {
        "id": "2VGDeCz_-Dy2"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define paths"
      ],
      "metadata": {
        "id": "nEX24bXTDRY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_annotated_folder = \"/content/drive/MyDrive/ASL_Project_Mika/Dataset_submission/annotated_train_data\"\n",
        "output_augmented_folder = \"/content/drive/MyDrive/ASL_Project_Mika/Dataset_submission/augmented_train_data\""
      ],
      "metadata": {
        "id": "KK88kBdW-Ky9"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "calls the function to generate 1 augmented version of each CSV in the annotated folder and save it to the augmented folder."
      ],
      "metadata": {
        "id": "6KdS3HL9DfJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "augment_all_csvs(\n",
        "    input_folder=input_annotated_folder,\n",
        "    output_folder=output_augmented_folder,\n",
        "    num_augmentations=1\n",
        ")"
      ],
      "metadata": {
        "id": "S1YIak_c_kMP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}